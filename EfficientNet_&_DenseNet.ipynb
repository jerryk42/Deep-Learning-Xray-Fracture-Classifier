{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4eO8rQYGPCOEBZB1npi5M"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet-B0"
      ],
      "metadata": {
        "id": "hrFjfePUksRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phWooWjhG823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f516fc45-f350-4a3b-fc5d-9c97363319fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/AUEB/MURA-v1.1.zip\" -d /content/\n"
      ],
      "metadata": {
        "id": "UlaDi7qdQlAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/MURA-v1.1/train_image_paths.csv')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "lbe9v594Qnch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5c0b00-35eb-4a0a-99bf-c0590395c8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\n",
            "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...                 \n",
            "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study...                 \n",
            "2  MURA-v1.1/train/XR_SHOULDER/patient00002/study...                 \n",
            "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study...                 \n",
            "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study...                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = pd.read_csv('/content/MURA-v1.1/train_image_paths.csv')\n",
        "print(df_train.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MPrAVjDbLW7",
        "outputId": "cd5e3bbe-1edc-41b6-c223-137363ff1705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df_train = pd.read_csv('/content/MURA-v1.1/train_image_paths.csv', header=None)\n",
        "df_train.columns = ['image_path']\n",
        "df_train['path'] = df_train['image_path'].apply(lambda x: os.path.join('/content', x))\n",
        "df_train['label'] = df_train['image_path'].apply(lambda x: 1 if 'positive' in x else 0)\n",
        "df_train['body_part'] = df_train['image_path'].apply(lambda x: x.split('/')[2])  # e.g., 'XR_SHOULDER'\n"
      ],
      "metadata": {
        "id": "S0aCNYrvQnaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a stratification key combining body part + label\n",
        "df_train['stratify_group'] = df_train['body_part'] + \"_\" + df_train['label'].astype(str)\n",
        "\n",
        "# Stratified 80/20 split\n",
        "df_train_final, df_val_final = train_test_split(\n",
        "    df_train,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_train['stratify_group']\n",
        ")"
      ],
      "metadata": {
        "id": "pOa1Y9ggR_XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the helper column\n",
        "df_train_final = df_train_final.drop(columns=['stratify_group'])\n",
        "df_val_final = df_val_final.drop(columns=['stratify_group'])"
      ],
      "metadata": {
        "id": "OfULCO_aSBkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/MURA-v1.1/valid_image_paths.csv', header=None)\n",
        "df_test.columns = ['image_path']\n",
        "df_test['path'] = df_test['image_path'].apply(lambda x: os.path.join('/content', x))\n",
        "df_test['label'] = df_test['image_path'].apply(lambda x: 1 if 'positive' in x else 0)\n",
        "df_test['body_part'] = df_test['image_path'].apply(lambda x: x.split('/')[2])  # e.g., XR_WRIST\n"
      ],
      "metadata": {
        "id": "w74fmyciQnYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode body_part as part_idx for conditioning\n",
        "body_parts = sorted(df_train_final['body_part'].unique())  # Ensure consistent order\n",
        "part_to_index = {part: idx for idx, part in enumerate(body_parts)}\n",
        "\n",
        "for df in [df_train_final, df_val_final, df_test]:\n",
        "    df['part_idx'] = df['body_part'].map(part_to_index)"
      ],
      "metadata": {
        "id": "RaBy1vdsvGn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution and Sanity Check\n",
        "\n",
        "print(\"Training set:\")\n",
        "print(df_train_final['body_part'].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nValidation set:\")\n",
        "print(df_val_final['body_part'].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "L9YI3eFKSGYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faab19a9-c156-400c-8479-861100383801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "body_part\n",
            "XR_WRIST       0.264960\n",
            "XR_SHOULDER    0.227637\n",
            "XR_HAND        0.150581\n",
            "XR_FINGER      0.138695\n",
            "XR_ELBOW       0.133974\n",
            "XR_FOREARM     0.049582\n",
            "XR_HUMERUS     0.034572\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Validation set:\n",
            "body_part\n",
            "XR_WRIST       0.264874\n",
            "XR_SHOULDER    0.227656\n",
            "XR_HAND        0.150638\n",
            "XR_FINGER      0.138821\n",
            "XR_ELBOW       0.133931\n",
            "XR_FOREARM     0.049579\n",
            "XR_HUMERUS     0.034501\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MuraDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row[\"image_path\"]\n",
        "        label = row[\"label\"]\n",
        "        part_idx = row[\"part_idx\"]\n",
        "\n",
        "        image = Image.open(image_path).convert(\"L\")  # \"L\" = grayscale\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, part_idx\n",
        "\n"
      ],
      "metadata": {
        "id": "uibKK4zQQnQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize before augmenting\n",
        "    transforms.RandomHorizontalFlip(p=0.5),   # Minor flip â€” common in medical images\n",
        "    transforms.RandomRotation(degrees=10),    # Small angle preserves structure\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Slight lighting changes\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # For grayscale\n",
        "\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # For grayscale\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "tPCRD98sQnVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Train\n",
        "train_dataset = MuraDataset(df_train_final, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# Validation\n",
        "val_dataset = MuraDataset(df_val_final, transform=val_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Test\n",
        "test_dataset = MuraDataset(df_test, transform=val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "3GiVGjyIWMDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiTask Model"
      ],
      "metadata": {
        "id": "45vHne4B7bq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1x224x224 input\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "class EfficientNetMultitask(nn.Module):\n",
        "    def __init__(self, num_body_parts=7, embed_dim=32, pretrained=True, num_views=3):\n",
        "        super(EfficientNetMultitask, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_views = num_views\n",
        "\n",
        "        # Load pretrained EfficientNet-B0\n",
        "        weights = 'DEFAULT' if pretrained else None\n",
        "        base = efficientnet_b0(weights=weights)\n",
        "\n",
        "        # Modify first conv layer to accept grayscale input (1 channel)\n",
        "        base.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.backbone = base.features\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        in_features = base.classifier[1].in_features  # 1280 for EfficientNet-B0\n",
        "\n",
        "        # Part embedding for fracture classification\n",
        "        self.part_embed = nn.Embedding(num_body_parts, embed_dim)\n",
        "\n",
        "        # Fracture head\n",
        "        self.fracture_head = nn.Sequential(\n",
        "            nn.Linear(in_features + embed_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "        # Body part classification head\n",
        "        self.bodypart_head = nn.Sequential(\n",
        "            nn.Linear(in_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_body_parts)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, part_idx):\n",
        "        # x: shape (B, 1, 224, 224) â†’ single grayscale image\n",
        "        features = self.backbone(x)\n",
        "        features = self.pool(features).squeeze(-1).squeeze(-1)  # shape: (B, 1280)\n",
        "\n",
        "        part_embedding = self.part_embed(part_idx)              # (B, embed_dim)\n",
        "\n",
        "        combined = torch.cat((features, part_embedding), dim=1) # (B, 1280 + embed_dim)\n",
        "        out_fracture = self.fracture_head(combined)\n",
        "        out_bodypart = self.bodypart_head(features)\n",
        "\n",
        "        return out_fracture, out_bodypart\n",
        "\n"
      ],
      "metadata": {
        "id": "8QwcQDC8EJgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define loss, optimizer, Scheduler"
      ],
      "metadata": {
        "id": "6Z_gLLMY7hHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "gwHg5iD2LQgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CrossEntropyLoss for both tasks\n",
        "fracture_loss_fn = nn.CrossEntropyLoss()\n",
        "bodypart_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate model\n",
        "model = EfficientNetMultitask(num_body_parts=len(part_to_index)).to(device)\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n"
      ],
      "metadata": {
        "id": "xgwsh6xt7g4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation Loops\n"
      ],
      "metadata": {
        "id": "8s5i7NH37m0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, fracture_loss_fn, bodypart_loss_fn):\n",
        "    model.train()\n",
        "    total_loss, correct_frac, correct_part = 0, 0, 0\n",
        "\n",
        "    for images, labels, part_idxs in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        part_idxs = part_idxs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out_fracture, out_bodypart = model(images, part_idxs)\n",
        "\n",
        "        loss_fracture = fracture_loss_fn(out_fracture, labels)\n",
        "        loss_bodypart = bodypart_loss_fn(out_bodypart, part_idxs)\n",
        "        loss = loss_fracture + loss_bodypart\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct_frac += (out_fracture.argmax(1) == labels).sum().item()\n",
        "        correct_part += (out_bodypart.argmax(1) == part_idxs).sum().item()\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss / len(loader), correct_frac / n, correct_part / n\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, fracture_loss_fn, bodypart_loss_fn):\n",
        "    model.eval()\n",
        "    total_loss, correct_frac, correct_part = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, part_idxs in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            out_fracture, out_bodypart = model(images, part_idxs)\n",
        "\n",
        "            loss_fracture = fracture_loss_fn(out_fracture, labels)\n",
        "            loss_bodypart = bodypart_loss_fn(out_bodypart, part_idxs)\n",
        "            loss = loss_fracture + loss_bodypart\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct_frac += (out_fracture.argmax(1) == labels).sum().item()\n",
        "            correct_part += (out_bodypart.argmax(1) == part_idxs).sum().item()\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss / len(loader), correct_frac / n, correct_part / n\n"
      ],
      "metadata": {
        "id": "HqueDowe7ftz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "IaEYHljQ7vmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "early_stop_patience = 5\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_fracture_acc, train_part_acc = train_one_epoch(model, train_loader, optimizer, fracture_loss_fn, bodypart_loss_fn)\n",
        "    val_loss, val_fracture_acc, val_part_acc = validate(model, val_loader, fracture_loss_fn, bodypart_loss_fn)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Frac Acc: {train_fracture_acc:.4f}, Part Acc: {train_part_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Frac Acc: {val_fracture_acc:.4f}, Part Acc: {val_part_acc:.4f}\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "        torch.save(model.state_dict(), \"efficientnet_multitask.pt\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"Early stop patience: {early_stop_counter}/5\")\n",
        "        if early_stop_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb2NM1rb7vaz",
        "outputId": "af026c85-f9a0-4b39-99c6-c31a865efa7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 0.8870, Frac Acc: 0.7151, Part Acc: 0.8997 | Val Loss: 0.5856, Frac Acc: 0.7766, Part Acc: 0.9709\n",
            "Epoch 2/20 | Train Loss: 0.5874, Frac Acc: 0.7786, Part Acc: 0.9704 | Val Loss: 0.5424, Frac Acc: 0.8044, Part Acc: 0.9745\n",
            "Epoch 3/20 | Train Loss: 0.5350, Frac Acc: 0.7997, Part Acc: 0.9772 | Val Loss: 0.5175, Frac Acc: 0.8097, Part Acc: 0.9770\n",
            "Epoch 4/20 | Train Loss: 0.5023, Frac Acc: 0.8093, Part Acc: 0.9811 | Val Loss: 0.5153, Frac Acc: 0.8135, Part Acc: 0.9761\n",
            "Epoch 5/20 | Train Loss: 0.4732, Frac Acc: 0.8212, Part Acc: 0.9831 | Val Loss: 0.5016, Frac Acc: 0.8222, Part Acc: 0.9783\n",
            "Epoch 6/20 | Train Loss: 0.4483, Frac Acc: 0.8296, Part Acc: 0.9847 | Val Loss: 0.5027, Frac Acc: 0.8244, Part Acc: 0.9789\n",
            "Early stop patience: 1/5\n",
            "Epoch 7/20 | Train Loss: 0.4290, Frac Acc: 0.8367, Part Acc: 0.9862 | Val Loss: 0.5211, Frac Acc: 0.8217, Part Acc: 0.9792\n",
            "Early stop patience: 2/5\n",
            "Epoch 8/20 | Train Loss: 0.4065, Frac Acc: 0.8434, Part Acc: 0.9892 | Val Loss: 0.4951, Frac Acc: 0.8286, Part Acc: 0.9788\n",
            "Epoch 9/20 | Train Loss: 0.3906, Frac Acc: 0.8484, Part Acc: 0.9898 | Val Loss: 0.5164, Frac Acc: 0.8196, Part Acc: 0.9791\n",
            "Early stop patience: 1/5\n",
            "Epoch 10/20 | Train Loss: 0.3699, Frac Acc: 0.8573, Part Acc: 0.9898 | Val Loss: 0.5175, Frac Acc: 0.8237, Part Acc: 0.9788\n",
            "Early stop patience: 2/5\n",
            "Epoch 11/20 | Train Loss: 0.3512, Frac Acc: 0.8635, Part Acc: 0.9913 | Val Loss: 0.5075, Frac Acc: 0.8309, Part Acc: 0.9804\n",
            "Early stop patience: 3/5\n",
            "Epoch 12/20 | Train Loss: 0.3047, Frac Acc: 0.8795, Part Acc: 0.9945 | Val Loss: 0.5112, Frac Acc: 0.8324, Part Acc: 0.9822\n",
            "Early stop patience: 4/5\n",
            "Epoch 13/20 | Train Loss: 0.2820, Frac Acc: 0.8886, Part Acc: 0.9954 | Val Loss: 0.5639, Frac Acc: 0.8276, Part Acc: 0.9806\n",
            "Early stop patience: 5/5\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Fracture"
      ],
      "metadata": {
        "id": "rZsxLMpf8Lnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, cohen_kappa_score\n",
        "\n",
        "def evaluate_fracture_task(model, test_loader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, part_idxs in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            out_fracture, _ = model(images, part_idxs)\n",
        "\n",
        "            probs = torch.softmax(out_fracture, dim=1)[:, 1].cpu().numpy()\n",
        "            preds = out_fracture.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    print(\"Fracture Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4))\n",
        "    print(\"ROC AUC Score:\", roc_auc_score(all_labels, all_probs))\n",
        "    print(\"Cohen's Kappa Score:\", cohen_kappa_score(all_labels, all_preds))\n"
      ],
      "metadata": {
        "id": "hjDTrftR8MEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Body Part"
      ],
      "metadata": {
        "id": "yidwOXqs8Txz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bodypart_task(model, loader, index_to_part=None):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_parts = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _, part_idxs in loader:\n",
        "            images = images.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            _, out_bodypart = model(images, part_idxs)\n",
        "            preds = out_bodypart.argmax(dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_parts.extend(part_idxs.cpu().numpy())\n",
        "\n",
        "    print(\"\\n--- Body Part Classification Report ---\")\n",
        "    if index_to_part:\n",
        "        target_names = [index_to_part[i] for i in sorted(set(all_parts))]\n",
        "    else:\n",
        "        target_names = None\n",
        "\n",
        "    print(classification_report(all_parts, all_preds, target_names=target_names, digits=4))\n"
      ],
      "metadata": {
        "id": "IL1uywzz8Uaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In case it's not already defined in current scope\n",
        "index_to_part = {v: k for k, v in part_to_index.items()}\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(\"efficientnet_multitask.pt\"))\n",
        "\n",
        "# Evaluate fracture classification and body part classification\n",
        "evaluate_fracture_task(model, test_loader)\n",
        "evaluate_bodypart_task(model, test_loader, index_to_part=index_to_part)\n"
      ],
      "metadata": {
        "id": "EJ4zAb588UYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9101ef-e1f2-4e5a-98d5-8d82e12ca3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fracture Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7665    0.9040    0.8296      1667\n",
            "           1     0.8700    0.7000    0.7758      1530\n",
            "\n",
            "    accuracy                         0.8064      3197\n",
            "   macro avg     0.8183    0.8020    0.8027      3197\n",
            "weighted avg     0.8161    0.8064    0.8039      3197\n",
            "\n",
            "ROC AUC Score: 0.8709520840929853\n",
            "Cohen's Kappa Score: 0.6089089510256505\n",
            "\n",
            "--- Body Part Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    XR_ELBOW     0.9502    0.9849    0.9673       465\n",
            "   XR_FINGER     0.9867    0.9631    0.9748       461\n",
            "  XR_FOREARM     0.9664    0.8605    0.9104       301\n",
            "     XR_HAND     0.9555    0.9804    0.9678       460\n",
            "  XR_HUMERUS     0.9716    0.9514    0.9614       288\n",
            " XR_SHOULDER     0.9808    1.0000    0.9903       563\n",
            "    XR_WRIST     0.9656    0.9803    0.9729       659\n",
            "\n",
            "    accuracy                         0.9681      3197\n",
            "   macro avg     0.9681    0.9601    0.9635      3197\n",
            "weighted avg     0.9683    0.9681    0.9678      3197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generalization Test on EfficientNet"
      ],
      "metadata": {
        "id": "plBByHnfA-fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "metadata": {
        "id": "LSzG9ZCSDkdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "fractured_dir = \"/content/drive/MyDrive/AUEB/Deep Learning/fractured\"\n",
        "not_fractured_dir = \"/content/drive/MyDrive/AUEB/Deep Learning/not fractured\"\n",
        "\n",
        "\n",
        "\n",
        "fractured_paths = glob(os.path.join(fractured_dir, '*'))\n",
        "not_fractured_paths = glob(os.path.join(not_fractured_dir, '*'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yt64kWauApJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Fractured images: {len(fractured_paths)}\")\n",
        "print(f\"Not fractured images: {len(not_fractured_paths)}\")\n",
        "print(f\"Total: {len(fractured_paths) + len(not_fractured_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orZ-7yLTC4Ha",
        "outputId": "6694ebfc-5c78-4b01-a846-1a2540431028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fractured images: 337\n",
            "Not fractured images: 492\n",
            "Total: 829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "class CustomXrayDataset(Dataset):\n",
        "    def __init__(self, image_paths, label, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.label = label  # 0 = no fracture, 1 = fracture\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"L\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.label, 0  # 0 = dummy body part index\n"
      ],
      "metadata": {
        "id": "JrF-nEwjApHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "fractured_ds = CustomXrayDataset(fractured_paths, label=1, transform=test_transform)\n",
        "notfractured_ds = CustomXrayDataset(not_fractured_paths, label=0, transform=test_transform)\n",
        "\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "combined_ds = ConcatDataset([fractured_ds, notfractured_ds])\n",
        "combined_loader = DataLoader(combined_ds, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "jsHtnr29ApE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels, part_idxs in combined_loader:\n",
        "        images = images.to(device)\n",
        "        part_idxs = part_idxs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        out_fracture, _ = model(images, part_idxs)\n",
        "        preds = out_fracture.argmax(1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "aaIbtXHqApCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Custom X-Ray Evaluation:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Not Fractured\", \"Fractured\"]))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSmgWLS8ApAi",
        "outputId": "faef5e6b-875c-47fd-811d-4f48f2a427f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom X-Ray Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Fractured       0.72      0.98      0.83       492\n",
            "    Fractured       0.94      0.44      0.60       337\n",
            "\n",
            "     accuracy                           0.76       829\n",
            "    macro avg       0.83      0.71      0.72       829\n",
            " weighted avg       0.81      0.76      0.74       829\n",
            "\n",
            "Confusion Matrix:\n",
            "[[482  10]\n",
            " [188 149]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet169"
      ],
      "metadata": {
        "id": "zmxR4GfpXnlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import densenet169\n",
        "\n",
        "class DenseNet169Multitask(nn.Module):\n",
        "    def __init__(self, num_body_parts=7, embed_dim=32, pretrained=True):\n",
        "        super(DenseNet169Multitask, self).__init__()\n",
        "\n",
        "        # Load pretrained DenseNet169\n",
        "        weights = 'IMAGENET1K_V1' if pretrained else None\n",
        "        base = densenet169(weights=weights)\n",
        "\n",
        "        # Modify first conv layer to accept grayscale (1 channel)\n",
        "        original_conv = base.features.conv0\n",
        "        base.features.conv0 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=original_conv.out_channels,\n",
        "            kernel_size=original_conv.kernel_size,\n",
        "            stride=original_conv.stride,\n",
        "            padding=original_conv.padding,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        self.features = base.features\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.feature_dim = base.classifier.in_features  # 1664 for DenseNet169\n",
        "\n",
        "        # Embedding for body part index\n",
        "        self.part_embed = nn.Embedding(num_body_parts, embed_dim)\n",
        "\n",
        "        # Fracture classification head\n",
        "        self.fracture_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim + embed_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "        # Body part classification head\n",
        "        self.bodypart_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_body_parts)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, part_idx):\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "\n",
        "        part_feat = self.part_embed(part_idx)\n",
        "        combined = torch.cat([x, part_feat], dim=1)\n",
        "        out_fracture = self.fracture_head(combined)\n",
        "        out_bodypart = self.bodypart_head(x)\n",
        "\n",
        "        return out_fracture, out_bodypart\n"
      ],
      "metadata": {
        "id": "22Z-IIIzWyRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "XKdHeEA_XQGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CrossEntropyLoss for both tasks\n",
        "fracture_loss_fn = nn.CrossEntropyLoss()\n",
        "bodypart_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate model\n",
        "model = DenseNet169Multitask(num_body_parts=len(part_to_index)).to(device)\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AYwbau9XQGd",
        "outputId": "d0413c94-7be1-4551-852c-3a81051f5b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54.7M/54.7M [00:00<00:00, 123MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, fracture_loss_fn, bodypart_loss_fn):\n",
        "    model.train()\n",
        "    total_loss, correct_frac, correct_part = 0, 0, 0\n",
        "\n",
        "    for images, labels, part_idxs in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        part_idxs = part_idxs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out_fracture, out_bodypart = model(images, part_idxs)\n",
        "\n",
        "        loss_fracture = fracture_loss_fn(out_fracture, labels)\n",
        "        loss_bodypart = bodypart_loss_fn(out_bodypart, part_idxs)\n",
        "        loss = loss_fracture + loss_bodypart\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct_frac += (out_fracture.argmax(1) == labels).sum().item()\n",
        "        correct_part += (out_bodypart.argmax(1) == part_idxs).sum().item()\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss / len(loader), correct_frac / n, correct_part / n\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, loader, fracture_loss_fn, bodypart_loss_fn):\n",
        "    model.eval()\n",
        "    total_loss, correct_frac, correct_part = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, part_idxs in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            out_fracture, out_bodypart = model(images, part_idxs)\n",
        "\n",
        "            loss_fracture = fracture_loss_fn(out_fracture, labels)\n",
        "            loss_bodypart = bodypart_loss_fn(out_bodypart, part_idxs)\n",
        "            loss = loss_fracture + loss_bodypart\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct_frac += (out_fracture.argmax(1) == labels).sum().item()\n",
        "            correct_part += (out_bodypart.argmax(1) == part_idxs).sum().item()\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss / len(loader), correct_frac / n, correct_part / n\n"
      ],
      "metadata": {
        "id": "NQUbX2p-XQGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "early_stop_patience = 5\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_fracture_acc, train_part_acc = train_one_epoch(model, train_loader, optimizer, fracture_loss_fn, bodypart_loss_fn)\n",
        "    val_loss, val_fracture_acc, val_part_acc = validate(model, val_loader, fracture_loss_fn, bodypart_loss_fn)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Frac Acc: {train_fracture_acc:.4f}, Part Acc: {train_part_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Frac Acc: {val_fracture_acc:.4f}, Part Acc: {val_part_acc:.4f}\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "        torch.save(model.state_dict(), \"DenseNet169Multitask.pt\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"Early stop patience: {early_stop_counter}/5\")\n",
        "        if early_stop_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ad3e9c-dc31-458a-960f-a1ea8f850e01",
        "id": "tn1PhirILC7T"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 0.8180, Frac Acc: 0.7226, Part Acc: 0.9219 | Val Loss: 0.6182, Frac Acc: 0.7683, Part Acc: 0.9643\n",
            "Epoch 2/20 | Train Loss: 0.5930, Frac Acc: 0.7793, Part Acc: 0.9697 | Val Loss: 0.5558, Frac Acc: 0.7886, Part Acc: 0.9747\n",
            "Epoch 3/20 | Train Loss: 0.5501, Frac Acc: 0.7936, Part Acc: 0.9764 | Val Loss: 0.5689, Frac Acc: 0.7896, Part Acc: 0.9724\n",
            "Early stop patience: 1/5\n",
            "Epoch 4/20 | Train Loss: 0.5165, Frac Acc: 0.8058, Part Acc: 0.9793 | Val Loss: 0.5273, Frac Acc: 0.8051, Part Acc: 0.9758\n",
            "Epoch 5/20 | Train Loss: 0.4904, Frac Acc: 0.8142, Part Acc: 0.9831 | Val Loss: 0.5254, Frac Acc: 0.8044, Part Acc: 0.9769\n",
            "Epoch 6/20 | Train Loss: 0.4697, Frac Acc: 0.8236, Part Acc: 0.9834 | Val Loss: 0.5226, Frac Acc: 0.8115, Part Acc: 0.9758\n",
            "Epoch 7/20 | Train Loss: 0.4520, Frac Acc: 0.8268, Part Acc: 0.9838 | Val Loss: 0.5257, Frac Acc: 0.8082, Part Acc: 0.9765\n",
            "Early stop patience: 1/5\n",
            "Epoch 8/20 | Train Loss: 0.4277, Frac Acc: 0.8357, Part Acc: 0.9874 | Val Loss: 0.5350, Frac Acc: 0.8028, Part Acc: 0.9775\n",
            "Early stop patience: 2/5\n",
            "Epoch 9/20 | Train Loss: 0.4085, Frac Acc: 0.8466, Part Acc: 0.9872 | Val Loss: 0.5222, Frac Acc: 0.8139, Part Acc: 0.9773\n",
            "Epoch 10/20 | Train Loss: 0.3888, Frac Acc: 0.8527, Part Acc: 0.9887 | Val Loss: 0.5306, Frac Acc: 0.8143, Part Acc: 0.9773\n",
            "Early stop patience: 1/5\n",
            "Epoch 11/20 | Train Loss: 0.3750, Frac Acc: 0.8579, Part Acc: 0.9895 | Val Loss: 0.5241, Frac Acc: 0.8174, Part Acc: 0.9796\n",
            "Early stop patience: 2/5\n",
            "Epoch 12/20 | Train Loss: 0.3564, Frac Acc: 0.8636, Part Acc: 0.9906 | Val Loss: 0.5301, Frac Acc: 0.8183, Part Acc: 0.9784\n",
            "Early stop patience: 3/5\n",
            "Epoch 13/20 | Train Loss: 0.2711, Frac Acc: 0.8948, Part Acc: 0.9958 | Val Loss: 0.5516, Frac Acc: 0.8210, Part Acc: 0.9819\n",
            "Early stop patience: 4/5\n",
            "Epoch 14/20 | Train Loss: 0.2371, Frac Acc: 0.9092, Part Acc: 0.9971 | Val Loss: 0.5649, Frac Acc: 0.8215, Part Acc: 0.9810\n",
            "Early stop patience: 5/5\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, cohen_kappa_score\n",
        "\n",
        "def evaluate_fracture_task(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, part_idxs in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            out_fracture, _ = model(images, part_idxs)\n",
        "\n",
        "            probs = torch.softmax(out_fracture, dim=1)[:, 1].cpu().numpy()\n",
        "            preds = out_fracture.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "\n",
        "    print(\"Fracture Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4))\n",
        "    print(\"ROC AUC Score:\", roc_auc_score(all_labels, all_probs))\n",
        "    print(\"Cohen's Kappa Score:\", cohen_kappa_score(all_labels, all_preds))\n"
      ],
      "metadata": {
        "id": "tKYATLRuW_lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bodypart_task(model, loader, index_to_part=None):\n",
        "    model.eval()\n",
        "    all_parts = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _, part_idxs in loader:\n",
        "            images = images.to(device)\n",
        "            part_idxs = part_idxs.to(device)\n",
        "\n",
        "            _, out_bodypart = model(images, part_idxs)\n",
        "            preds = out_bodypart.argmax(dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_parts.extend(part_idxs.cpu().numpy())\n",
        "\n",
        "    print(\"\\n--- Body Part Classification Report ---\")\n",
        "    if index_to_part:\n",
        "        target_names = [index_to_part[i] for i in sorted(set(all_parts))]\n",
        "    else:\n",
        "        target_names = None\n",
        "\n",
        "    print(classification_report(all_parts, all_preds, target_names=target_names, digits=4))\n"
      ],
      "metadata": {
        "id": "QwYr-KeZW_lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In case it's not already defined in current scope\n",
        "index_to_part = {v: k for k, v in part_to_index.items()}\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(\"DenseNet169Multitask.pt\"))\n",
        "\n",
        "# Evaluate fracture classification and body part classification\n",
        "evaluate_fracture_task(model, test_loader)\n",
        "evaluate_bodypart_task(model, test_loader, index_to_part=index_to_part)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c9c4fb-fce2-4177-bf01-2b326fff953f",
        "id": "TQh3l_8sW_lc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fracture Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7515    0.8980    0.8183      1667\n",
            "           1     0.8589    0.6765    0.7569      1530\n",
            "\n",
            "    accuracy                         0.7920      3197\n",
            "   macro avg     0.8052    0.7872    0.7876      3197\n",
            "weighted avg     0.8029    0.7920    0.7889      3197\n",
            "\n",
            "ROC AUC Score: 0.8540966316540614\n",
            "Cohen's Kappa Score: 0.579549668297902\n",
            "\n",
            "--- Body Part Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    XR_ELBOW     0.9197    0.9849    0.9512       465\n",
            "   XR_FINGER     0.9781    0.9675    0.9727       461\n",
            "  XR_FOREARM     0.9446    0.8505    0.8951       301\n",
            "     XR_HAND     0.9634    0.9739    0.9686       460\n",
            "  XR_HUMERUS     0.9849    0.9062    0.9439       288\n",
            " XR_SHOULDER     0.9824    0.9911    0.9867       563\n",
            "    XR_WRIST     0.9599    0.9818    0.9707       659\n",
            "\n",
            "    accuracy                         0.9615      3197\n",
            "   macro avg     0.9619    0.9509    0.9556      3197\n",
            "weighted avg     0.9620    0.9615    0.9612      3197\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visuals"
      ],
      "metadata": {
        "id": "YEBopiH1D2MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def efficientnet_multitask_architecture():\n",
        "    dot = Digraph(comment='EfficientNet Multi-task Architecture')\n",
        "    dot.attr(rankdir='TB', splines='spline', nodesep='0.6', ranksep='0.5')\n",
        "\n",
        "    # Inputs\n",
        "    dot.node('input', 'Input Image\\n(224Ã—224)', shape='ellipse', style='filled', fillcolor='#DDEEFF')\n",
        "    dot.node('part_idx', 'Body Part Index\\n(int)', shape='ellipse', style='filled', fillcolor='#DDEEFF')\n",
        "\n",
        "    # Image path\n",
        "    dot.node('efficientnet', 'EfficientNet-B0\\nfeatures', shape='box', style='filled', fillcolor='#A3C1DA')\n",
        "    dot.node('gap', 'AdaptiveAvgPool2d\\nâ†’ (B, 1280)', shape='box', style='filled', fillcolor='#A3C1DA')\n",
        "\n",
        "    # Embedding path\n",
        "    dot.node('embed', 'Embedding Layer\\n(num_parts â†’ 32)', shape='box', style='filled', fillcolor='#C7E9C0')\n",
        "\n",
        "    # Body part prediction head\n",
        "    dot.node('body_fc1', 'Linear(1280 â†’ 128)\\nReLU + Dropout', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('body_fc2', 'Linear(128 â†’ 7)\\nPart Output', shape='box', style='filled', fillcolor='#FFCCCC')\n",
        "\n",
        "    # Merge\n",
        "    dot.node('concat', 'Concatenate\\n[Features + Part Embedding]', shape='diamond', style='filled', fillcolor='#FBE8A6')\n",
        "\n",
        "    # Fracture prediction head\n",
        "    dot.node('fracture_fc1', 'Linear(1312 â†’ 512)\\nReLU + Dropout', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('fracture_fc2', 'Linear(512 â†’ 256)\\nReLU + Dropout', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('fracture_fc3', 'Linear(256 â†’ 2)\\nFracture Output', shape='box', style='filled', fillcolor='#FFCCCC')\n",
        "\n",
        "    # Connections\n",
        "    dot.edge('input', 'efficientnet')\n",
        "    dot.edge('efficientnet', 'gap')\n",
        "    dot.edge('gap', 'body_fc1')\n",
        "    dot.edge('body_fc1', 'body_fc2')\n",
        "    dot.edge('gap', 'concat')\n",
        "    dot.edge('part_idx', 'embed')\n",
        "    dot.edge('embed', 'concat')\n",
        "    dot.edge('concat', 'fracture_fc1')\n",
        "    dot.edge('fracture_fc1', 'fracture_fc2')\n",
        "    dot.edge('fracture_fc2', 'fracture_fc3')\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Generate and display\n",
        "efficientnet_diagram = efficientnet_multitask_architecture()\n",
        "efficientnet_diagram.render(filename='efficientnet_multitask_architecture', format='png', cleanup=False)\n",
        "display(efficientnet_diagram)\n"
      ],
      "metadata": {
        "id": "RXJlZOmkmrMl",
        "outputId": "24d87495-9193-486e-9ec3-f94fa0392f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"533pt\" height=\"559pt\"\n viewBox=\"0.00 0.00 533.00 559.48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 555.48)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-555.48 529,-555.48 529,4 -4,4\"/>\n<!-- input -->\n<g id=\"node1\" class=\"node\">\n<title>input</title>\n<ellipse fill=\"#ddeeff\" stroke=\"black\" cx=\"122\" cy=\"-524.61\" rx=\"58.88\" ry=\"26.74\"/>\n<text text-anchor=\"middle\" x=\"122\" y=\"-528.41\" font-family=\"Times,serif\" font-size=\"14.00\">Input Image</text>\n<text text-anchor=\"middle\" x=\"122\" y=\"-513.41\" font-family=\"Times,serif\" font-size=\"14.00\">(224Ã—224)</text>\n</g>\n<!-- efficientnet -->\n<g id=\"node3\" class=\"node\">\n<title>efficientnet</title>\n<polygon fill=\"#a3c1da\" stroke=\"black\" points=\"174,-453.87 70,-453.87 70,-415.87 174,-415.87 174,-453.87\"/>\n<text text-anchor=\"middle\" x=\"122\" y=\"-438.67\" font-family=\"Times,serif\" font-size=\"14.00\">EfficientNet&#45;B0</text>\n<text text-anchor=\"middle\" x=\"122\" y=\"-423.67\" font-family=\"Times,serif\" font-size=\"14.00\">features</text>\n</g>\n<!-- input&#45;&gt;efficientnet -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;efficientnet</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-497.29C122,-486.84 122,-474.8 122,-464.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-464.11 122,-454.11 118.5,-464.11 125.5,-464.11\"/>\n</g>\n<!-- part_idx -->\n<g id=\"node2\" class=\"node\">\n<title>part_idx</title>\n<ellipse fill=\"#ddeeff\" stroke=\"black\" cx=\"349\" cy=\"-434.87\" rx=\"74.91\" ry=\"26.74\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-438.67\" font-family=\"Times,serif\" font-size=\"14.00\">Body Part Index</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-423.67\" font-family=\"Times,serif\" font-size=\"14.00\">(int)</text>\n</g>\n<!-- embed -->\n<g id=\"node5\" class=\"node\">\n<title>embed</title>\n<polygon fill=\"#c7e9c0\" stroke=\"black\" points=\"408.5,-372 289.5,-372 289.5,-334 408.5,-334 408.5,-372\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-356.8\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding Layer</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\">(num_parts â†’ 32)</text>\n</g>\n<!-- part_idx&#45;&gt;embed -->\n<g id=\"edge6\" class=\"edge\">\n<title>part_idx&#45;&gt;embed</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349,-407.72C349,-399.53 349,-390.46 349,-382.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"352.5,-382.12 349,-372.12 345.5,-382.12 352.5,-382.12\"/>\n</g>\n<!-- gap -->\n<g id=\"node4\" class=\"node\">\n<title>gap</title>\n<polygon fill=\"#a3c1da\" stroke=\"black\" points=\"185.5,-372 58.5,-372 58.5,-334 185.5,-334 185.5,-372\"/>\n<text text-anchor=\"middle\" x=\"122\" y=\"-356.8\" font-family=\"Times,serif\" font-size=\"14.00\">AdaptiveAvgPool2d</text>\n<text text-anchor=\"middle\" x=\"122\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\">â†’ (B, 1280)</text>\n</g>\n<!-- efficientnet&#45;&gt;gap -->\n<g id=\"edge2\" class=\"edge\">\n<title>efficientnet&#45;&gt;gap</title>\n<path fill=\"none\" stroke=\"black\" d=\"M122,-415.75C122,-405.84 122,-393.35 122,-382.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-382.05 122,-372.05 118.5,-382.05 125.5,-382.05\"/>\n</g>\n<!-- body_fc1 -->\n<g id=\"node6\" class=\"node\">\n<title>body_fc1</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"130,-279 0,-279 0,-241 130,-241 130,-279\"/>\n<text text-anchor=\"middle\" x=\"65\" y=\"-263.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(1280 â†’ 128)</text>\n<text text-anchor=\"middle\" x=\"65\" y=\"-248.8\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU + Dropout</text>\n</g>\n<!-- gap&#45;&gt;body_fc1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>gap&#45;&gt;body_fc1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M110.47,-333.58C102.22,-320.42 91,-302.51 81.77,-287.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"84.6,-285.69 76.32,-279.08 78.67,-289.41 84.6,-285.69\"/>\n</g>\n<!-- concat -->\n<g id=\"node8\" class=\"node\">\n<title>concat</title>\n<polygon fill=\"#fbe8a6\" stroke=\"black\" points=\"349,-298 173,-260 349,-222 525,-260 349,-298\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-263.8\" font-family=\"Times,serif\" font-size=\"14.00\">Concatenate</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-248.8\" font-family=\"Times,serif\" font-size=\"14.00\">[Features + Part Embedding]</text>\n</g>\n<!-- gap&#45;&gt;concat -->\n<g id=\"edge5\" class=\"edge\">\n<title>gap&#45;&gt;concat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M167.12,-333.91C199.17,-321.07 242.81,-303.57 279.31,-288.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280.93,-292.06 288.91,-285.09 278.33,-285.56 280.93,-292.06\"/>\n</g>\n<!-- embed&#45;&gt;concat -->\n<g id=\"edge7\" class=\"edge\">\n<title>embed&#45;&gt;concat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349,-333.58C349,-326.19 349,-317.29 349,-308.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"352.5,-308.19 349,-298.19 345.5,-308.19 352.5,-308.19\"/>\n</g>\n<!-- body_fc2 -->\n<g id=\"node7\" class=\"node\">\n<title>body_fc2</title>\n<polygon fill=\"#ffcccc\" stroke=\"black\" points=\"120,-186 10,-186 10,-148 120,-148 120,-186\"/>\n<text text-anchor=\"middle\" x=\"65\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(128 â†’ 7)</text>\n<text text-anchor=\"middle\" x=\"65\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\">Part Output</text>\n</g>\n<!-- body_fc1&#45;&gt;body_fc2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>body_fc1&#45;&gt;body_fc2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M65,-240.58C65,-227.92 65,-210.86 65,-196.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"68.5,-196.08 65,-186.08 61.5,-196.08 68.5,-196.08\"/>\n</g>\n<!-- fracture_fc1 -->\n<g id=\"node9\" class=\"node\">\n<title>fracture_fc1</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"414,-186 284,-186 284,-148 414,-148 414,-186\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(1312 â†’ 512)</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU + Dropout</text>\n</g>\n<!-- concat&#45;&gt;fracture_fc1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>concat&#45;&gt;fracture_fc1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349,-221.99C349,-213.36 349,-204.32 349,-196.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"352.5,-196.03 349,-186.03 345.5,-196.03 352.5,-196.03\"/>\n</g>\n<!-- fracture_fc2 -->\n<g id=\"node10\" class=\"node\">\n<title>fracture_fc2</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"410.5,-112 287.5,-112 287.5,-74 410.5,-74 410.5,-112\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(512 â†’ 256)</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU + Dropout</text>\n</g>\n<!-- fracture_fc1&#45;&gt;fracture_fc2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>fracture_fc1&#45;&gt;fracture_fc2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349,-147.83C349,-140.13 349,-130.97 349,-122.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"352.5,-122.41 349,-112.41 345.5,-122.41 352.5,-122.41\"/>\n</g>\n<!-- fracture_fc3 -->\n<g id=\"node11\" class=\"node\">\n<title>fracture_fc3</title>\n<polygon fill=\"#ffcccc\" stroke=\"black\" points=\"404,-38 294,-38 294,0 404,0 404,-38\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(256 â†’ 2)</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Fracture Output</text>\n</g>\n<!-- fracture_fc2&#45;&gt;fracture_fc3 -->\n<g id=\"edge10\" class=\"edge\">\n<title>fracture_fc2&#45;&gt;fracture_fc3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349,-73.83C349,-66.13 349,-56.97 349,-48.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"352.5,-48.41 349,-38.41 345.5,-48.41 352.5,-48.41\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d1245dbff50>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "from IPython.display import display\n",
        "\n",
        "def densenet169_multitask_architecture():\n",
        "    dot = Digraph(comment='DenseNet169 Multi-task Architecture')\n",
        "    dot.attr(rankdir='TB', splines='spline', nodesep='0.6', ranksep='0.5')\n",
        "\n",
        "    # Input & Part index\n",
        "    dot.node('input', 'Input Image\\n(224Ã—224)', shape='ellipse', style='filled', fillcolor='#DDEEFF')\n",
        "    dot.node('part_idx', 'Body Part Index\\n(int)', shape='ellipse', style='filled', fillcolor='#DDEEFF')\n",
        "\n",
        "    # DenseNet path\n",
        "    dot.node('densenet', 'DenseNet169\\n(Features Only)', shape='box', style='filled', fillcolor='#A3C1DA')\n",
        "    dot.node('pool', 'AdaptiveAvgPool2d\\nâ†’ (B, 1664)', shape='box', style='filled', fillcolor='#A3C1DA')\n",
        "\n",
        "    # Embedding path\n",
        "    dot.node('embed', 'Embedding Layer\\n(num_parts â†’ 32)', shape='box', style='filled', fillcolor='#C7E9C0')\n",
        "\n",
        "    # Part prediction\n",
        "    dot.node('body_fc1', 'Linear(1664 â†’ 128)\\nReLU + Dropout(0.3)', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('body_fc2', 'Linear(128 â†’ num_parts)\\nBody Part Output', shape='box', style='filled', fillcolor='#FFCCCC')\n",
        "\n",
        "    # Merge\n",
        "    dot.node('concat', 'Concatenate\\n[1664 + 32]', shape='diamond', style='filled', fillcolor='#FBE8A6')\n",
        "\n",
        "    # Fracture classification head\n",
        "    dot.node('fracture_fc1', 'Linear(1696 â†’ 512)\\nBN + ReLU + Dropout(0.4)', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('fracture_fc2', 'Linear(512 â†’ 256)\\nReLU + Dropout(0.3)', shape='box', style='filled', fillcolor='#FDD9D9')\n",
        "    dot.node('fracture_fc3', 'Linear(256 â†’ 2)\\nFracture Output', shape='box', style='filled', fillcolor='#FFCCCC')\n",
        "\n",
        "    # Connections\n",
        "    dot.edge('input', 'densenet')\n",
        "    dot.edge('densenet', 'pool')\n",
        "    dot.edge('pool', 'body_fc1')\n",
        "    dot.edge('body_fc1', 'body_fc2')\n",
        "    dot.edge('pool', 'concat')\n",
        "    dot.edge('part_idx', 'embed')\n",
        "    dot.edge('embed', 'concat')\n",
        "    dot.edge('concat', 'fracture_fc1')\n",
        "    dot.edge('fracture_fc1', 'fracture_fc2')\n",
        "    dot.edge('fracture_fc2', 'fracture_fc3')\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Generate and display\n",
        "densenet_diagram = densenet169_multitask_architecture()\n",
        "densenet_diagram.render(filename='densenet169_multitask_architecture', format='png', cleanup=False)\n",
        "display(densenet_diagram)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "tABeZMkj06qs",
        "outputId": "0bfa58ee-c563-4eb5-d6f1-6b90a5db3ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"383pt\" height=\"559pt\"\n viewBox=\"0.00 0.00 383.00 559.48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 555.48)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-555.48 379,-555.48 379,4 -4,4\"/>\n<!-- input -->\n<g id=\"node1\" class=\"node\">\n<title>input</title>\n<ellipse fill=\"#ddeeff\" stroke=\"black\" cx=\"103.5\" cy=\"-524.61\" rx=\"58.88\" ry=\"26.74\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-528.41\" font-family=\"Times,serif\" font-size=\"14.00\">Input Image</text>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-513.41\" font-family=\"Times,serif\" font-size=\"14.00\">(224Ã—224)</text>\n</g>\n<!-- densenet -->\n<g id=\"node3\" class=\"node\">\n<title>densenet</title>\n<polygon fill=\"#a3c1da\" stroke=\"black\" points=\"154.5,-453.87 52.5,-453.87 52.5,-415.87 154.5,-415.87 154.5,-453.87\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-438.67\" font-family=\"Times,serif\" font-size=\"14.00\">DenseNet169</text>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-423.67\" font-family=\"Times,serif\" font-size=\"14.00\">(Features Only)</text>\n</g>\n<!-- input&#45;&gt;densenet -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;densenet</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-497.29C103.5,-486.84 103.5,-474.8 103.5,-464.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-464.11 103.5,-454.11 100,-464.11 107,-464.11\"/>\n</g>\n<!-- part_idx -->\n<g id=\"node2\" class=\"node\">\n<title>part_idx</title>\n<ellipse fill=\"#ddeeff\" stroke=\"black\" cx=\"285.5\" cy=\"-434.87\" rx=\"74.91\" ry=\"26.74\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-438.67\" font-family=\"Times,serif\" font-size=\"14.00\">Body Part Index</text>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-423.67\" font-family=\"Times,serif\" font-size=\"14.00\">(int)</text>\n</g>\n<!-- embed -->\n<g id=\"node5\" class=\"node\">\n<title>embed</title>\n<polygon fill=\"#c7e9c0\" stroke=\"black\" points=\"345,-372 226,-372 226,-334 345,-334 345,-372\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-356.8\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding Layer</text>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\">(num_parts â†’ 32)</text>\n</g>\n<!-- part_idx&#45;&gt;embed -->\n<g id=\"edge6\" class=\"edge\">\n<title>part_idx&#45;&gt;embed</title>\n<path fill=\"none\" stroke=\"black\" d=\"M285.5,-407.72C285.5,-399.53 285.5,-390.46 285.5,-382.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"289,-382.12 285.5,-372.12 282,-382.12 289,-382.12\"/>\n</g>\n<!-- pool -->\n<g id=\"node4\" class=\"node\">\n<title>pool</title>\n<polygon fill=\"#a3c1da\" stroke=\"black\" points=\"167,-372 40,-372 40,-334 167,-334 167,-372\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-356.8\" font-family=\"Times,serif\" font-size=\"14.00\">AdaptiveAvgPool2d</text>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\">â†’ (B, 1664)</text>\n</g>\n<!-- densenet&#45;&gt;pool -->\n<g id=\"edge2\" class=\"edge\">\n<title>densenet&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-415.75C103.5,-405.84 103.5,-393.35 103.5,-382.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-382.05 103.5,-372.05 100,-382.05 107,-382.05\"/>\n</g>\n<!-- body_fc1 -->\n<g id=\"node6\" class=\"node\">\n<title>body_fc1</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"156,-279 19,-279 19,-241 156,-241 156,-279\"/>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-263.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(1664 â†’ 128)</text>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-248.8\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU + Dropout(0.3)</text>\n</g>\n<!-- pool&#45;&gt;body_fc1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>pool&#45;&gt;body_fc1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M100.26,-333.58C98.01,-320.8 94.98,-303.52 92.43,-289.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"95.86,-288.32 90.68,-279.08 88.96,-289.53 95.86,-288.32\"/>\n</g>\n<!-- concat -->\n<g id=\"node8\" class=\"node\">\n<title>concat</title>\n<polygon fill=\"#fbe8a6\" stroke=\"black\" points=\"285.5,-298 202.5,-260 285.5,-222 368.5,-260 285.5,-298\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-263.8\" font-family=\"Times,serif\" font-size=\"14.00\">Concatenate</text>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-248.8\" font-family=\"Times,serif\" font-size=\"14.00\">[1664 + 32]</text>\n</g>\n<!-- pool&#45;&gt;concat -->\n<g id=\"edge5\" class=\"edge\">\n<title>pool&#45;&gt;concat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M139.89,-333.8C167.91,-319.8 206.88,-300.31 237.46,-285.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"239.27,-288.03 246.65,-280.42 236.14,-281.76 239.27,-288.03\"/>\n</g>\n<!-- embed&#45;&gt;concat -->\n<g id=\"edge7\" class=\"edge\">\n<title>embed&#45;&gt;concat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M285.5,-333.58C285.5,-326.19 285.5,-317.29 285.5,-308.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"289,-308.19 285.5,-298.19 282,-308.19 289,-308.19\"/>\n</g>\n<!-- body_fc2 -->\n<g id=\"node7\" class=\"node\">\n<title>body_fc2</title>\n<polygon fill=\"#ffcccc\" stroke=\"black\" points=\"161,-186 0,-186 0,-148 161,-148 161,-186\"/>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(128 â†’ num_parts)</text>\n<text text-anchor=\"middle\" x=\"80.5\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\">Body Part Output</text>\n</g>\n<!-- body_fc1&#45;&gt;body_fc2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>body_fc1&#45;&gt;body_fc2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.08,-240.58C85.11,-227.92 83.8,-210.86 82.69,-196.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"86.15,-195.78 81.89,-186.08 79.17,-196.32 86.15,-195.78\"/>\n</g>\n<!-- fracture_fc1 -->\n<g id=\"node9\" class=\"node\">\n<title>fracture_fc1</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"375,-186 204,-186 204,-148 375,-148 375,-186\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(1696 â†’ 512)</text>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\">BN + ReLU + Dropout(0.4)</text>\n</g>\n<!-- concat&#45;&gt;fracture_fc1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>concat&#45;&gt;fracture_fc1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.1,-222.51C287.48,-213.85 287.89,-204.73 288.25,-196.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"291.75,-196.4 288.7,-186.25 284.76,-196.09 291.75,-196.4\"/>\n</g>\n<!-- fracture_fc2 -->\n<g id=\"node10\" class=\"node\">\n<title>fracture_fc2</title>\n<polygon fill=\"#fdd9d9\" stroke=\"black\" points=\"358,-112 221,-112 221,-74 358,-74 358,-112\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(512 â†’ 256)</text>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU + Dropout(0.3)</text>\n</g>\n<!-- fracture_fc1&#45;&gt;fracture_fc2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>fracture_fc1&#45;&gt;fracture_fc2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-147.83C289.5,-140.13 289.5,-130.97 289.5,-122.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-122.41 289.5,-112.41 286,-122.41 293,-122.41\"/>\n</g>\n<!-- fracture_fc3 -->\n<g id=\"node11\" class=\"node\">\n<title>fracture_fc3</title>\n<polygon fill=\"#ffcccc\" stroke=\"black\" points=\"344.5,-38 234.5,-38 234.5,0 344.5,0 344.5,-38\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Linear(256 â†’ 2)</text>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Fracture Output</text>\n</g>\n<!-- fracture_fc2&#45;&gt;fracture_fc3 -->\n<g id=\"edge10\" class=\"edge\">\n<title>fracture_fc2&#45;&gt;fracture_fc3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-73.83C289.5,-66.13 289.5,-56.97 289.5,-48.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-48.41 289.5,-38.41 286,-48.41 293,-48.41\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d1245bffbd0>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyOGYrLkf7R8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}